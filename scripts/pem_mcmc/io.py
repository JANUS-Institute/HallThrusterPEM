import math
import os
from os import PathLike
from pathlib import Path

import numpy as np
from amisc import System

from pem_mcmc.types import Array, Number


def load_system(directory: Path) -> System:
    """
    Given a directory, find the first yaml file in that directory and load the amisc system from that file.
    """
    dir_contents = os.listdir(directory)
    for file_or_dir in dir_contents:
        # Skip directories
        if os.path.isdir(file_or_dir):
            continue

        # Skip files without .yml or .yaml extensions
        file = Path(file_or_dir)
        ext = file.suffix.casefold()
        if ext not in {".yml", ".yaml"}:
            continue

        # Load the system from the file
        return System.load_from_file(directory / file)

    # If we're here, we didn't find anything and should error.
    raise ValueError(f"Could not find a yaml file in directory {directory}.")


def append_sample_row(
    logfile: PathLike, sample_index: int, sample: Array, logp: Number, accepted: bool, delimiter: str = ','
):
    """Append a row of MCMC diagnostic data for the given `logfile`"""
    id_str = f"{sample_index:06d}"
    with open(logfile, "a") as fd:
        row = [id_str] + [f"{s}" for s in sample] + [f"{logp}", f"{accepted}"]
        print(delimiter.join(row), file=fd)


def read_dlm(file: PathLike, delimiter: str | None = ',', comments='#') -> dict[str, Array]:
    """Read a simple delimited file consisting of headers and numerical data into a dict that maps names to columns"""
    with open(file, 'r') as fd:
        header = fd.readline().rstrip()
        if header.startswith(comments):
            header = header[1:].lstrip()

    col_names = header.split(delimiter)
    table_data = np.atleast_2d(np.genfromtxt(file, skip_header=1, delimiter=delimiter))
    columns = [table_data[:, i] for i in range(len(col_names))]
    return {col_name: column for (col_name, column) in zip(col_names, columns)}


def read_output_file(path: PathLike, burn_fraction: float = 0.0):
    """
    Read an output file generated by MCMC.
    TODO: use read_dlm for this.
    """
    dlm = ","
    with open(path, "r") as file:
        header = file.readline().rstrip()

        fields = header.split(dlm)
        var_start = 1
        var_end = len(fields) - 2

        id_ind = 0
        variables = fields[var_start:var_end]
        log_post_ind = len(variables) + 1
        accept_ind = len(variables) + 2

        assert fields[id_ind] == "id"
        assert fields[log_post_ind] == "log_posterior"
        assert fields[accept_ind] == "accepted"

        samples = []
        logposts = []
        accepted = []
        ids = []

        for i, line in enumerate(file):
            fields = line.rstrip().split(dlm)
            accept_str = fields[accept_ind].casefold()

            if accept_str == "true":
                accept = True
            elif accept_str == "false":
                accept = False
            else:
                raise ValueError(f"Invalid accept value {fields[accept_ind]} at row {i} in file {path}.")

            if accept:
                # Create IDs from scratch rather than read ID.
                # This is for compatibility with older runs where a bug led to some duplicate ids.
                id = f"{i:06d}"
                ids.append(id)

            elif len(ids) > 0:
                ids.append(ids[-1])
            else:
                raise ValueError(f"No accepted sample prior to sample {i}")

            logposts.append(float(fields[log_post_ind]))
            samples.append(np.array([float(x) for x in fields[var_start:var_end]]))
            accepted.append(accept)

    # Discard burned samples
    if burn_fraction > 0:
        num_burn = math.floor(burn_fraction * len(samples))
        samples = samples[num_burn:]
        logposts = logposts[num_burn:]
        accepted = accepted[num_burn:]
        ids = ids[num_burn:]

    return variables, np.array(samples), np.array(logposts), np.array(accepted), ids
