{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started","text":"<p>Prototype of a predictive engineering model (PEM) of a Hall thruster. Integrates sub-models from multiple disciplines to simulate a Hall thruster operating in a vacuum chamber. Uses uncertainty quantification techniques to extrapolate model predictions to a space-like environment.</p>"},{"location":"#installation","title":"Installation","text":"<p>We highly recommend using pdm: <pre><code>pip install --user pdm\ngit clone https://github.com/JANUS-Institute/HallThrusterPEM.git\ncd HallThrusterPEM\npdm install\n</code></pre></p>"},{"location":"#quickstart","title":"Quickstart","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom hallmd.models.pem import pem_v0\nfrom hallmd.data.loader import spt100_data\nfrom hallmd.utils import plot_qoi\n\nsystem = pem_v0()\nsystem.fit(max_iter=10)\n\n# Show model predictions vs experimental thrust data\ndata = spt100_data(['T'])[0]\ninputs = data['x']  # Pressure, Anode voltage, Anode mass flow rate\nNx, num_samples = inputs.shape[0], 100\nxs = np.zeros((Nx, num_samples, len(system.exo_vars)))\n\nfor i in range(Nx):\n    nominal = dict(PB=inputs[i, 0], Va=inputs[i, 1], mdot_a=inputs[i, 2])\n    xs[i, :, :] = system.sample_inputs(num_samples, use_pdf=True, nominal=nominal)\n\nys = system.predict(xs, qoi_ind='T')*1000       # Predicted thrust [mN]\ny = data['y']*1000                              # Experimental thrust [mN]\ny_err = 2 * np.sqrt(data['var_y'])*1000         # Experimental noise [mN]\n\nfig, ax = plt.subplots()\npressure = 10 ** data[:, 0]\nidx = np.argsort(pressure)\nax.errorbar(pressure, y, yerr=y_err, fmt='or', capsize=3, label='Experiment')\nplot_qoi(ax, pressure[idx], ys[idx, :], 'Background pressure (Torr)', 'Thrust (mN)', legend=True)\nplt.show()\n</code></pre>"},{"location":"#viewing-the-docs","title":"Viewing the docs","text":"<p>The documentation can be viewed locally with the <code>mkdocs</code> utility: <pre><code>cd HallThrusterPEM\npdm run docs         # Open http://127.0.0.1:8000/ in a browser to view\n</code></pre> Eventually this will be made public when the project is made open-source.</p>"},{"location":"#project-structure","title":"Project structure","text":"<pre><code>HallThrusterPEM                 # Root project directory\n|- docs                         # Documentation and references\n|- scripts                      # Scripts for building PEM surrogates\n|  |- pem_v0                    # PEM v0 surrogate scripts\n|  |  |- gen_data.sh\n|  |  |- train_surr.sh\n|  |- debug                     # Scripts for debugging SLURM workflow\n|  |- analysis                  # Scripts for UQ analysis (Monte Carlo, Sobol, etc.)\n|  |- ...\n|- src/hallmd                   # Python package source code root\n|  |- models                    # Python wrappers for sub-models\n|  |  |- thruster.py\n|  |  |- ...\n|  |- data                      # Experimental data\n|  |  |- spt100                 # Contains all data for the SPT-100\n|  |  |- ...\n|  |  |- loader.py              # Helper functions for loading data\n|  |- utils.py                  # Useful utility functions\n|  |- juliapkg.json             # Specifies version of Hallthruster.jl\n|- tests                        # Testing for models, generating data, and plotting results\n|- results                      # Test scripts write data here (but kept out of the repo)\n|- pdm.lock                     # Frozen dependencies file\n|- setup_env.sh                 # Convenience script for setting up pdm environment\n</code></pre>"},{"location":"#contributing","title":"Contributing","text":"<p>See the contribution guidelines.</p>"},{"location":"#citations","title":"Citations","text":"<p>Coming soon.</p>"},{"location":"CONTRIBUTING/","title":"Contributing","text":""},{"location":"CONTRIBUTING/#contributing-to-hallmd","title":"Contributing to <code>hallmd</code>","text":"<p>You might be here if you want to:</p> <ul> <li>Report a bug</li> <li>Discuss the current state of the code</li> <li>Submit a fix</li> <li>Propose a new feature</li> <li>Write unit tests</li> <li>Add to the documentation</li> </ul> <p>We use Github to host code and documentation, to track issues and feature requests, and to accept pull requests.</p>"},{"location":"CONTRIBUTING/#submitting-pull-requests","title":"Submitting pull requests","text":"<p>Pull requests are the best way to propose changes to the codebase (bug fixes, new features, docs, etc.)</p> <ol> <li>Clone the repo and create your branch from <code>main</code>. </li> <li>If you are adding a feature or making major changes, first create the issue. </li> <li>If you've added code that should be tested, add to <code>/tests</code>. </li> <li>If you've made major changes, update the <code>/docs</code>. </li> <li>Ensure the test suite passes (<code>pdm run test</code>).</li> <li>Follow Conventional commits guidelines when adding a commit message.</li> <li>Issue that pull request!</li> </ol> <p>We strongly recommend using pdm to set up your development environment. An example contribution workflow is shown here:</p> <pre><code>pip install --user pdm\ngit clone https://github.com/JANUS-Institute/HallThrusterPEM.git\ncd HallThrusterPEM\npdm install\ngit checkout -b &lt;your-branch-name&gt;\n\n# Make local changes\n\npdm run test  # make sure tests pass\ngit add -A\ngit commit -m \"Adding a bugfix or new feature\"\ngit push -u origin &lt;your-branch-name&gt;\n\n# Go to Github and \"Compare &amp; Pull Request\" on your branch\n# For your PR to be merged:\n  # squash all your commits on your branch (interactively in an IDE most likely)\n  # rebase to the top of origin/main to include new changes from others\n\ngit fetch\ngit rebase -i main your-branch  # for example\n\n# Resolve any conflicts\n# Your history now looks something like this:\n#              o your-branch\n#             /\n# ---o---o---o main\n\n# You can delete the branch when your PR has been merged\n</code></pre> <p>You can also find a good tutorial here.</p>"},{"location":"CONTRIBUTING/#report-bugs-using-issues","title":"Report bugs using issues","text":"<p>Open a new issue and describe your problem using the template. Provide screenshots where possible and example log files. Add labels to help categorize and describe your issue.</p>"},{"location":"CONTRIBUTING/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under its GNU GPLv3 License.</p>"},{"location":"how-to-guides/","title":"How-to Guides","text":""},{"location":"how-to-guides/#how-to-construct-a-predictive-engineering-model-pem","title":"How to construct a \"predictive\" engineering model (PEM)","text":"<ol> <li>First, break the system into individual components, for example the cathode, the discharge channel, the far-field plume, etc. Define all the inputs and outputs of each component and how they connect to each other. Variables that get mapped from the output of one component into the input of another component are termed \"coupling\" variables, while all other inputs are called system \"exogenous\" variables.</li> <li>Write a Python wrapper function for each component model, following the <code>amisc</code> package guidelines. See examples for the cathode, thruster, and plume models. By convention, these functions are placed in the <code>hallmd.models</code> subdirectory.</li> <li>Construct an <code>amisc.SystemSurrogate</code> object that links all the component models in a multidisciplinary system. See the example for pem_v0. Variables are specified in and loaded from a <code>.json</code> configuration file in the <code>hallmd.models.config</code> directory. Other model configurations can also go here.</li> <li>You can test your system using the <code>SystemSurrogate</code> object.</li> </ol> <p>Example</p> <p><pre><code>from hallmd.models.pem import your_pem\n\npem_obj = your_pem()\ninputs  = pem_obj.sample_inputs(100)                 # (100, input_dim)\noutputs = pem_obj.predict(inputs, use_model='best')  # (100, output_dim)\n</code></pre> This will evaluate all the component models directly using the \"best\" available model, which will be the highest fidelity specified in your wrapper functions. It typically won't be feasible to do this with a large number of inputs, so next you will want to train the <code>pem_obj</code> surrogate to approximate the true system model.</p>"},{"location":"how-to-guides/#how-to-train-a-surrogate-for-the-pem","title":"How to train a surrogate for the PEM","text":"<p>This guide assumes you have access to a Linux HPC system. It will use specific examples for the Great Lakes system at the University of Michigan, which uses the <code>SLURM</code> workload manager and the <code>Lmod</code> environment module. Regardless, this guide can be adapted to your specific system as needed. We assume you have a terminal connection open on the system you are using.</p> <ol> <li>Clone this repository and change into the root project directory: <pre><code>git clone https://github.com/JANUS-Institute/HallThrusterPEM.git\ncd HallThrusterPEM\n</code></pre></li> <li>Source the setup script in the shell: <pre><code>source setup_env.sh\n</code></pre> This will make sure you have the <code>pdm</code> tool installed, a proper version of Python loaded, the <code>mpi4py</code> library installed, and all required SLURM environment variables defined. You will need to edit this script for your specific usage, for example adding your SLURM account info, commenting out <code>pdm add mpi4py</code> if you do not have an MPI-enabled system, etc. The main idea here is to set up a working Python virtual environment with all resources defined and loaded.</li> <li>Create a new directory in the <code>scripts</code> folder with the name of your new \"PEM\" system. The <code>scripts/pem_v0</code> contains everything used to build the original 3-component PEM; it may be easiest to simply copy this directory as a template and name it <code>pem_vi</code> for \\(i &gt; 0\\).</li> <li>Look at the <code>[tool.pdm.scripts]</code> section of <code>pyproject.toml</code>. There are three convenience scripts provided that can be run with the command <code>pdm run script_name</code>: the important ones are <code>gen_data</code>, <code>fit</code>, and <code>train</code>.</li> <li>The <code>gen_data</code> script will call <code>sbatch scripts/your_pem/gen_data.sh</code> which then calls <code>gen_data.py</code>. This is responsible for generating all the data needed by the models and surrogate before training the surrogate. For example, <code>pem_v0</code> relies on <code>gen_data</code> to make a test set and some compression-related data that get copied over to the <code>hallmd.models.config</code> directory. At the very least, you will likely need this to make a test set for evaluating the performance of the surrogate during training.</li> <li>The <code>fit</code> script will call <code>sbatch scripts/your_pem/fit_surr.sh</code> which then calls <code>fit_surr.py</code>. This is responsible for actually loading your <code>SystemSurrogate</code> object and training the surrogate via: <pre><code>from hallmd.models.pem import your_pem\n\npem_obj = your_pem()\nyour_pem.fit(max_iter=100, max_runtime_hr=3)  # for example\n</code></pre></li> <li>The <code>train</code> script is an expedient for calling <code>gen_data</code> and <code>fit</code> in sequence, with the latter being dependent on the successful completion of the first.</li> </ol> <p>TLDR; Complete working example</p> <pre><code>git clone https://github.com/JANUS-Institute/HallThrusterPEM.git\ncd HallThrusterPEM\n\n# Make your specific edits to setup_env.sh\n\nsource setup_env.sh\n\n# Make a scripts/pem_v1 folder and edit the gen_data, fit_surr, etc. files\n\npdm train pem_v1\n</code></pre>"},{"location":"how-to-guides/#how-to-use-the-surrogate-after-training","title":"How to use the surrogate after training","text":"<p>Surrogate training is performed with the <code>amisc.SystemSurrogate.fit</code> function. You should specify a save directory for the <code>SystemSurrogate</code> object, which will create a folder with the hierarchy: <pre><code>amisc_2024_timestamp     # Root surrogate directory\n|- components            # Model output files may optionally be saved here\n|  |- Cathode\n|  |- Thruster\n|  |- etc.\n|- sys                   # Surrogate save files\n|  |- sys_init.pkl\n|  |- etc.\n|  |- sys_final.pkl\n|- 2024_timestamp.log    # Training log (useful for debugging)\n</code></pre> You can freely distribute the standalone <code>.pkl</code> save files and reload the surrogate using the <code>load_from_file()</code> function: <pre><code>from amisc.system import SystemSurrogate\n\nfile = 'sys_final.pkl'\nsurr = SystemSurrogate.load_from_file(file)\n</code></pre></p> <p>Note</p> <p>It is more advisable to distribute the whole <code>amisc_timestamp</code> directory and load the save file from within <code>amisc_timestamp/sys/sys_final.pkl</code>, since the directory structure will be recreated from a standalone file regardless.</p>"},{"location":"how-to-guides/#how-to-use-the-surrogate-for-uncertainty-quantification","title":"How to use the surrogate for uncertainty quantification","text":"<p>There are four more scripts provided in <code>scripts/pem_v0</code> that were used to run all UQ analyses for the original 3-component PEM:</p> <ol> <li><code>plot_slice.py</code> -- Loads the surrogate from a training save <code>.pkl</code> file and plots several \"1d slices\" of inputs and outputs and compares to the true model output. This is useful for gauging how good the surrogate approximation is.</li> <li><code>mcmc.py</code> -- Contains several functions for maximum-likelihood estimation, obtaining a Laplace estimate of the posterior, and Markov-Chain Monte Carlo (MCMC) sampling using the <code>uqtils</code> package. Use this for calibration of the PEM model parameters using the surrogate.</li> <li><code>monte_carlo.py</code> -- Samples the uncertain inputs and propagates through the surrogate to get output uncertainty. Has several plotting functions for comparing model predictions to experimental data.</li> <li><code>sobol.py</code> -- Performs a Sobol' sensitivity analysis using the surrogate and the <code>uqtils</code> package. Has several plotting functions for showing Sobol' indices for each component model.</li> </ol> <p>Note</p> <p>It is advisable to copy all these files from <code>pem_v0</code> and adapt them for your new <code>pem_vXX</code>. They are written quite specific to the use case, but can serve as a good starting point for your own scripts.</p>"},{"location":"theory/","title":"Overview","text":"<p>Coming soon.</p>"},{"location":"tutorials/","title":"Tutorials","text":"<p>Coming soon.</p>"},{"location":"reference/cathode/","title":"Cathode","text":"<p><code>cc.py</code></p> <p>Module for cathode coupling models.</p>"},{"location":"reference/cathode/#hallmd.models.cc--includes","title":"Includes","text":"<ul> <li><code>cc_feedforward()</code> - only feedforward cathode coupling model with pressure dependence (Jorns 2021)</li> <li><code>cc_feedback()</code> - same model but modified to include feedback from the plume</li> </ul>"},{"location":"reference/cathode/#hallmd.models.cc.cc_feedback","title":"<code>cc_feedback(cc_input)</code>","text":"<p>Cathode coupling with feedback interactions with the plume.</p> PARAMETER  DESCRIPTION <code>cc_input</code> <p>the named model inputs in a dictionary</p> <p> </p> RETURNS DESCRIPTION <p><code>dict(cathode_potential=res)</code></p> Source code in <code>src/hallmd/models/cc.py</code> <pre><code>def cc_feedback(cc_input):\n    \"\"\"Cathode coupling with feedback interactions with the plume.\n\n    :param cc_input: the named model inputs in a dictionary\n    :returns: `dict(cathode_potential=res)`\n    \"\"\"\n    # Load cathode inputs\n    Te = cc_input['cathode_electron_temp_eV']\n    V_vac = cc_input['V_vac']\n    Pstar = cc_input['Pstar'] * TORR_2_PA\n    c_prime = cc_input['c_prime']\n    PB = cc_input['background_pressure_Torr'] * TORR_2_PA\n    TB = cc_input['background_temperature_K']\n    ui_avg = cc_input['avg_ion_velocity']           # avg ion exit velocity from thruster\n    ji_T = cc_input['cathode_current_density']      # total current density at cathode location\n    Va = cc_input['anode_potential']\n\n    # Equation 12 in Jorns and Byrne, Plasma Sources Sci. Technol. 30 (2021) 015012\n    n_e = ji_T / (Q_E * ui_avg)\n    PT = (n_e*kB*TB) / c_prime\n    V_cc = V_vac + Te * np.log(1 + PB / PT) - (Te / (PT + Pstar)) * PB\n\n    # Threshold between 0 and anode voltage\n    V_cc = min(Va, max(0, V_cc))\n\n    return {'cathode_potential': V_cc}\n</code></pre>"},{"location":"reference/cathode/#hallmd.models.cc.cc_feedforward","title":"<code>cc_feedforward(x)</code>","text":"<p>Compute cathode coupling model with no feedback interactions.</p> PARAMETER  DESCRIPTION <code>x</code> <p><code>(..., xdim)</code>, Cathode model inputs</p> <p> TYPE: <code>ndarray</code> </p> RETURNS DESCRIPTION <p><code>(..., ydim)</code>, Cathode model outputs</p> Source code in <code>src/hallmd/models/cc.py</code> <pre><code>def cc_feedforward(x: np.ndarray):\n    \"\"\"Compute cathode coupling model with no feedback interactions.\n\n    :param x: `(..., xdim)`, Cathode model inputs\n    :returns y: `(..., ydim)`, Cathode model outputs\n    \"\"\"\n    # Load inputs\n    x = np.atleast_1d(x)\n    PB = 10 ** (x[..., 0, np.newaxis]) * TORR_2_PA      # Background Pressure (log10 Torr)\n    Va = x[..., 1, np.newaxis]                          # Anode voltage\n    Te = x[..., 2, np.newaxis]                          # Electron temperature (eV)\n    V_vac = x[..., 3, np.newaxis]                       # Vacuum coupling voltage (V)\n    Pstar = x[..., 4, np.newaxis] * 1e-6 * TORR_2_PA    # Model parameter P*\n    PT = x[..., 5, np.newaxis] * 1e-6 * TORR_2_PA       # Model parameter P_T\n\n    # Compute cathode coupling voltage\n    y = V_vac + Te * np.log(1 + PB / PT) - (Te / (PT + Pstar)) * PB\n    y[y &lt; 0] = 0\n    ind = np.where(y &gt; Va)\n    y[ind] = Va[ind]\n    return {'y': y, 'cost': 1}\n</code></pre>"},{"location":"reference/data/","title":"Summary","text":"<p>The <code>hallmd.data</code> package contains a folder for each unique thruster. The experimental data for each thruster is further divided by folders for each individual paper or reference. The raw experimental data is contained within these  folders in any arbitrary format (hdf4, json, csv, etc.). Each set of raw experimental data should come with a  <code>dataloader.py</code> file that reads from the raw data into standardized Python objects. Any additional documentation for the datasets is encouraged (e.g. citations, descriptions, summaries, etc.) and can be included in the data folders.</p>"},{"location":"reference/data/#thrusters","title":"Thrusters","text":"<ul> <li>SPT-100 - currently the only available thruster.</li> </ul>"},{"location":"reference/data/#top-level-loaderpy","title":"Top-level <code>loader.py</code>","text":"<p>This module provides high-level convenience functions for loading data for specific thrusters. If you plan to add experimental data for a new thruster, this would be a good location for a wrapper function to load this data.</p> <p><code>loader.py</code></p> <p>Module for loading experimental data for specific thrusters.</p>"},{"location":"reference/data/#hallmd.data.loader--includes","title":"Includes","text":"<ul> <li><code>spt100_data()</code> - loads data for the SPT-100</li> </ul> <p>Loading raw data</p> <p>Raw data is loaded as best as possible into a standard format from any raw data source (.csv, .json, .hdf, etc.). The raw data files are included where possible along with wrapper Python <code>dataloader</code> functions that manage prepping the standard format. When adding new data to the repository, create a new folder for each thruster and always include corresponding <code>dataloader.py</code> files. You can then add top-level loaders for thrusters like <code>spt100_data()</code> here.</p> <p>The standard data format</p> <p>Data from a single experiment is loaded as best as possible into a Python <code>dict</code> with four fields: <code>[x, y, loc, var_y]</code> as explained in the example below. The experimental operating conditions <code>x</code> should be framed in the same units and format as any of your models would expect. Likewise, the measurements <code>y</code> should be directly comparable to the predictions of your models. <code>loc</code> is optional, but should be used when your data has spatial or temporal dependence (use <code>loc</code> in these cases to specify the Cartesian, spherical, etc. coordinates where the measurements were taken). <code>var_y</code> summarizes experimental noise in terms of additive Gaussian white noise with this variance. <pre><code>data = dict(x=x,  # `(N, x_dim)` `np.ndarray` with `x_dim` experimental operating conditions for `N` data points\n            y=y,  # `(N, y_dim)` `np.ndarray` with measurements of `y_dim` QoIs, corresponding to the `N` samples\n            loc=loc,      # `(N, loc_dim)`, array with the `loc_dim` coordinates where the QoIs were measured\n            var_y=var_y,  # `(N, y_dim)`, array with the experimental noise variance for all measurements\n            )\n</code></pre></p>"},{"location":"reference/data/#hallmd.data.loader.spt100_data","title":"<code>spt100_data(qois=None)</code>","text":"<p>Return a dict with experimental data for each specified quantity for the SPT-100.</p> PARAMETER  DESCRIPTION <code>qois</code> <p>a list specifying the experimental data to return, must be in <code>['V_cc', 'T', 'uion', 'jion']</code></p> <p> TYPE: <code>list[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>dict[str:list[ExpData]]</code> <p>map of <code>qoi-&gt;data</code>, where <code>data</code> is a list of experimental data sets</p> Source code in <code>src/hallmd/data/loader.py</code> <pre><code>def spt100_data(qois: list[str] = None) -&gt; dict[str: list[ExpData]]:\n    \"\"\"Return a dict with experimental data for each specified quantity for the SPT-100.\n\n    :param qois: a list specifying the experimental data to return, must be in `['V_cc', 'T', 'uion', 'jion']`\n    :returns: map of `qoi-&gt;data`, where `data` is a list of experimental data sets\n    \"\"\"\n    if qois is None:\n        qois = ['V_cc', 'T', 'uion', 'jion', 'I_D']\n    exp_data = dict()\n\n    # Load Vcc data\n    if 'V_cc' in qois:\n        from .spt100.diamant2014.dataloader import load_vcc\n        exp_data['V_cc'] = [load_vcc()]\n\n    # Load thrust data\n    if 'T' in qois:\n        from .spt100.diamant2014.dataloader import load_thrust as thrust1\n        from .spt100.sankovic1993.dataloader import load_thrust as thrust2\n        exp_data['T'] = [thrust1(), thrust2()]\n\n    # Load discharge current data\n    if 'I_D' in qois:\n        from .spt100.sankovic1993.dataloader import load_discharge_current\n        exp_data['I_D'] = [load_discharge_current()]\n\n    # Load ion velocity data\n    if 'uion' in qois:\n        from .spt100.macdonald2019.dataloader import load_uion\n        exp_data['uion'] = [load_uion()]\n\n    # Load ion velocity data\n    if 'jion' in qois:\n        from .spt100.diamant2014.dataloader import load_jion\n        exp_data['jion'] = [load_jion()]\n\n    return exp_data\n</code></pre>"},{"location":"reference/models/","title":"Summary","text":"<p>All models are specified in <code>hallmd.models</code>. Currently supported models are based on a three-component feedforward system for a Hall thruster:</p> <ol> <li>Cathode - Accounts for interactions of the cathode plasma with the main discharge.</li> <li>Thruster - The primary simulation of the Hall thruster channel discharge and near-field.</li> <li>Plume - Models the far-field expansion of the plasma plume in the vacuum chamber.</li> </ol> <p>Individual component models are integrated into a predictive engineering model (PEM) multidisciplinary system in <code>hallmd.models.pem</code>.</p>"},{"location":"reference/models/#model-configuration","title":"Model configuration","text":"<p>Component models can optionally retrieve external configuration data from the <code>hallmd.models.config</code> directory. For  example, <code>Hallthruster.jl</code> obtains magnetic field information from <code>bfield_spt100.csv</code> stored in the <code>config</code> directory,  as well as additional configurations from <code>hallthruster_jl.json</code>.</p>"},{"location":"reference/overview/","title":"Overview","text":"<p>Coming soon.</p>"},{"location":"reference/pem/","title":"PEM","text":"<p><code>pem.py</code></p> <p>Module for full multidisciplinary Hall thruster predictive engineering model(s).</p> <p>Note</p> <p>Multidisciplinary systems are specified using the <code>SystemSurrogate</code> object from the <code>amisc</code> package. This data structure allows feedforward and feedback connections between a set of component models. It can be used to build a surrogate for the MD system, or to evaluate the system directly using the underlying component models.</p>"},{"location":"reference/pem/#hallmd.models.pem--includes","title":"Includes","text":"<ul> <li><code>pem_v0()</code> - The v0 cathode-thruster-plume feedforward multidisciplinary system.</li> </ul>"},{"location":"reference/pem/#hallmd.models.pem.pem_v0","title":"<code>pem_v0(save_dir=None, executor=None, init=True, hf_override=False, var_file=CONFIG_DIR / 'variables_v0.json', from_file=None)</code>","text":"<p>Return a <code>SystemSurrogate</code> object for the feedforward v0 PEM system.</p> PARAMETER  DESCRIPTION <code>save_dir</code> <p>where to save surrogate and model outputs</p> <p> TYPE: <code>str | Path</code> DEFAULT: <code>None</code> </p> <code>executor</code> <p>the parallel execution manager</p> <p> TYPE: <code>Executor</code> DEFAULT: <code>None</code> </p> <code>init</code> <p>whether to initialize the surrogate (will evaluate all component models)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>hf_override</code> <p>whether to use only highest-fidelity for all models</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>var_file</code> <p>the path to the <code>.json</code> config file storing information about all variables</p> <p> TYPE: <code>str | Path</code> DEFAULT: <code>CONFIG_DIR / 'variables_v0.json'</code> </p> <code>from_file</code> <p>the <code>.pkl</code> save file to load the surrogate from, (instead of building from scratch)</p> <p> TYPE: <code>str | Path</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>SystemSurrogate</code> <p>the <code>SystemSurrogate</code> object</p> Source code in <code>src/hallmd/models/pem.py</code> <pre><code>def pem_v0(save_dir: str | Path = None, executor: Executor = None, init: bool = True,\n           hf_override: bool = False, var_file: str | Path = CONFIG_DIR / 'variables_v0.json',\n           from_file: str | Path = None) -&gt; SystemSurrogate:\n    \"\"\"Return a `SystemSurrogate` object for the feedforward v0 PEM system.\n\n    :param save_dir: where to save surrogate and model outputs\n    :param executor: the parallel execution manager\n    :param init: whether to initialize the surrogate (will evaluate all component models)\n    :param hf_override: whether to use only highest-fidelity for all models\n    :param var_file: the path to the `.json` config file storing information about all variables\n    :param from_file: the `.pkl` save file to load the surrogate from, (instead of building from scratch)\n    :returns: the `SystemSurrogate` object\n    \"\"\"\n    exo_vars = load_variables(['PB', 'Va', 'mdot_a', 'T_ec', 'V_vac', 'P*', 'PT', 'u_n', 'l_t', 'vAN1', 'vAN2',\n                               'delta_z', 'z0', 'p0', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'sigma_cex', 'r_m'],\n                              var_file)\n    coupling_vars = load_variables(['V_cc', 'I_B0', 'I_D', 'T', 'eta_v', 'eta_c', 'eta_m', 'ui_avg', 'theta_d'], var_file)\n\n    if from_file is not None:\n        surr = SystemSurrogate.load_from_file(Path(from_file), stdout=False, executor=executor)\n        for v in exo_vars:\n            # Make sure nominal values are up to date with the current config file\n            j = surr.exo_vars.index(v)\n            surr.exo_vars[j] = v\n            for node, node_obj in surr.graph.nodes.items():\n                try:\n                    j = surr[node].x_vars.index(v)\n                    surr[node].x_vars[j] = v\n                except:\n                    pass\n\n        for v in coupling_vars:\n            j = surr.coupling_vars.index(v)\n            surr.coupling_vars[j].tex = v.tex\n            surr.coupling_vars[j].nominal = v.nominal\n\n        return surr\n\n    # Get number of reconstruction coefficients for ion velocity and ion current density profiles\n    try:\n        with open(CONFIG_DIR / 'thruster_svd.pkl', 'rb') as fd, open(CONFIG_DIR / 'plume_svd.pkl', 'rb') as fd2:\n            d = pickle.load(fd)\n            r1 = d['vtr'].shape[0]\n            d2 = pickle.load(fd2)\n            r2 = d2['vtr'].shape[0]\n    except FileNotFoundError:\n        r1 = 4\n        r2 = 2\n\n    coupling_vars.extend([UniformRV(-20, 20, id=f'uion{i}', tex=f\"$\\\\tilde{{u}}_{{ion,{i}}}$\",\n                                    description=f'Ion velocity latent coefficient {i}',\n                                    param_type='coupling') for i in range(r1)])\n    coupling_vars.extend([UniformRV(-20, 20, id=f'jion{i}', tex=f\"$\\\\tilde{{j}}_{{ion,{i}}}$\",\n                                    description=f'Current density latent coefficient {i}',\n                                    param_type='coupling') for i in range(r2)])\n\n    # Component inputs\n    cathode_exo = ['PB', 'Va', 'T_ec', 'V_vac', 'P*', 'PT']\n    thruster_exo = ['PB', 'Va', 'mdot_a', 'T_ec', 'u_n', 'l_t', 'vAN1', 'vAN2', 'delta_z', 'z0', 'p0']\n    plume_exo = ['PB', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'sigma_cex', 'r_m']\n\n    # Models should be specified at the global scope for pickling\n    cathode = ComponentSpec(cc_feedforward, name='Cathode', exo_in=cathode_exo, coupling_out='V_cc',\n                            surrogate='analytical')\n    thruster = ComponentSpec(hallthruster_jl_wrapper, name='Thruster', exo_in=thruster_exo, truth_alpha=(2, 2),\n                             max_alpha=(2, 2), coupling_in='V_cc', max_beta=(2,)*(len(thruster_exo)+1), save_output=True,\n                             coupling_out=['I_B0', 'I_D', 'T', 'eta_v', 'eta_c', 'eta_m', 'ui_avg'] + [f'uion{i}' for i in range(r1)],\n                             model_kwargs=dict(n_jobs=-1, compress=True, hf_override=hf_override))\n    plume = ComponentSpec(plume_feedforward, name='Plume', exo_in=plume_exo, coupling_in='I_B0', surrogate='analytical',\n                          coupling_out=['theta_d'] + [f'jion{i}' for i in range(r2)], model_kwargs={'compress': True})\n\n    logger_name = 'SF-surrogate' if hf_override else 'MF-surrogate'\n    surr = SystemSurrogate([cathode, thruster, plume], exo_vars, coupling_vars, executor=executor, init_surr=init,\n                           stdout=False, save_dir=save_dir, logger_name=logger_name)\n\n    return surr\n</code></pre>"},{"location":"reference/plume/","title":"Plume","text":"<p><code>plume.py</code></p> <p>Module for Hall thruster plume models.</p>"},{"location":"reference/plume/#hallmd.models.plume--includes","title":"Includes","text":"<ul> <li><code>plume_feedforward()</code> - Semi-empirical feedforward plume model.</li> <li><code>jion_reconstruct()</code> - Convenience function for reconstructing ion current density profiles from compressed data.</li> </ul>"},{"location":"reference/plume/#hallmd.models.plume.jion_reconstruct","title":"<code>jion_reconstruct(xr, alpha=None, svd_data=CONFIG_DIR / 'plume_svd.pkl')</code>","text":"<p>Reconstruct an ion current density profile, interpolate to <code>alpha</code> if provided.</p> <p>Warning</p> <p>The <code>svd_file</code> must be the same as was used when originally compressing the data in <code>plume_feedforward()</code>.</p> PARAMETER  DESCRIPTION <code>xr</code> <p><code>(... r)</code> The reduced dimension output of <code>plume_feedforward()</code>, (just the ion current density)</p> <p> TYPE: <code>ndarray</code> </p> <code>alpha</code> <p><code>(Nx,)</code> The alpha grid points to interpolate to (in radians, between -pi/2 and pi/2)</p> <p> TYPE: <code>ndarray</code> DEFAULT: <code>None</code> </p> <code>svd_data</code> <p>Path to <code>.pkl</code> SVD data file for compressing the ion current density profile, can also pass the <code>dict</code> of svd data directly in</p> <p> TYPE: <code>dict | str | Path</code> DEFAULT: <code>CONFIG_DIR / 'plume_svd.pkl'</code> </p> RETURNS DESCRIPTION <code>tuple[ndarray, ndarray]</code> <p><code>alpha</code>, <code>jion_interp</code> - <code>(..., Nx or M)</code> The reconstructed (and optionally interpolated) jion profile(s), corresponds to <code>alpha=(0, 90)</code> deg with <code>M=100</code> points by default</p> Source code in <code>src/hallmd/models/plume.py</code> <pre><code>def jion_reconstruct(xr: np.ndarray, alpha: np.ndarray = None,\n                     svd_data: dict | str | Path = CONFIG_DIR / 'plume_svd.pkl') -&gt; tuple[np.ndarray, np.ndarray]:\n    \"\"\"Reconstruct an ion current density profile, interpolate to `alpha` if provided.\n\n    !!! Warning\n        The `svd_file` must be the same as was used when originally compressing the data in `plume_feedforward()`.\n\n    :param xr: `(... r)` The reduced dimension output of `plume_feedforward()`, (just the ion current density)\n    :param alpha: `(Nx,)` The alpha grid points to interpolate to (in radians, between -pi/2 and pi/2)\n    :param svd_data: Path to `.pkl` SVD data file for compressing the ion current density profile, can also pass the\n                     `dict` of svd data directly in\n    :returns: `alpha`, `jion_interp` - `(..., Nx or M)` The reconstructed (and optionally interpolated) jion profile(s),\n                    corresponds to `alpha=(0, 90)` deg with `M=100` points by default\n    \"\"\"\n    if not isinstance(svd_data, dict):\n        with open(svd_data, 'rb') as fd:\n            svd_data = pickle.load(fd)\n    vtr = svd_data['vtr']       # (r x M)\n    A = svd_data['A']\n    A_mu = np.mean(A, axis=0)\n    A_std = np.std(A, axis=0)\n    r, M = vtr.shape\n\n    alpha_g = np.linspace(0, np.pi/2, M, dtype=xr.dtype)\n    jion_g = (np.squeeze(vtr.T @ xr[..., np.newaxis], axis=-1) * A_std + A_mu).astype(xr.dtype)  # (..., M)\n\n    # Do interpolation\n    if alpha is not None:\n        # Extend to range (-90, 90) deg\n        alpha_g2 = np.concatenate((-np.flip(alpha_g)[:-1], alpha_g))                     # (2M-1,)\n        jion_g2 = np.concatenate((np.flip(jion_g, axis=-1)[..., :-1], jion_g), axis=-1)  # (..., 2M-1)\n\n        f = interp1d(alpha_g2, jion_g2, axis=-1)\n        jion_interp = f(alpha)  # (..., Nx)\n        return alpha, jion_interp\n    else:\n        return alpha_g, jion_g\n</code></pre>"},{"location":"reference/plume/#hallmd.models.plume.plume_feedforward","title":"<code>plume_feedforward(x, compress=False, svd_data=CONFIG_DIR / 'plume_svd.pkl')</code>","text":"<p>Compute the semi-empirical ion current density (\\(j_{ion}\\)) plume model.</p> PARAMETER  DESCRIPTION <code>x</code> <p><code>(..., xdim)</code> Plume inputs</p> <p> TYPE: <code>ndarray</code> </p> <code>compress</code> <p>Whether to return the dimension-reduced \\(j_{ion}\\) profile</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>svd_data</code> <p>Path to <code>.pkl</code> SVD data file for compressing the ion current density profile, or can directly pass in the svd data as a <code>dict</code></p> <p> TYPE: <code>dict | str | Path</code> DEFAULT: <code>CONFIG_DIR / 'plume_svd.pkl'</code> </p> RETURNS DESCRIPTION <p><code>y</code> - <code>(..., ydim)</code> Plume outputs</p> RAISES DESCRIPTION <code>ModelRunException</code> <p>if anything fails</p> Source code in <code>src/hallmd/models/plume.py</code> <pre><code>def plume_feedforward(x: np.ndarray, compress: bool = False,\n                      svd_data: dict | str | Path = CONFIG_DIR / 'plume_svd.pkl'):\n    \"\"\"Compute the semi-empirical ion current density ($j_{ion}$) plume model.\n\n    :param x: `(..., xdim)` Plume inputs\n    :param compress: Whether to return the dimension-reduced $j_{ion}$ profile\n    :param svd_data: Path to `.pkl` SVD data file for compressing the ion current density profile, or can directly\n                     pass in the svd data as a `dict`\n    :raises ModelRunException: if anything fails\n    :returns: `y` - `(..., ydim)` Plume outputs\n    \"\"\"\n    # Load plume inputs\n    P_B = 10 ** (x[..., 0, np.newaxis]) * TORR_2_PA     # Background pressure (Torr log10)\n    c0 = x[..., 1, np.newaxis]                          # Fit coefficients\n    c1 = x[..., 2, np.newaxis]\n    c2 = x[..., 3, np.newaxis]\n    c3 = x[..., 4, np.newaxis]\n    c4 = 10 ** (x[..., 5, np.newaxis])\n    c5 = 10 ** (x[..., 6, np.newaxis])\n    sigma_cex = x[..., 7, np.newaxis] * 1e-20           # Charge-exchange cross-section (m^2)\n    r_m = x[..., 8, np.newaxis]                         # Axial distance from thruster exit plane (m)\n    I_B0 = x[..., 9, np.newaxis]                        # Total initial ion beam current (A)\n\n    # Load svd params for dimension reduction\n    if compress:\n        if not isinstance(svd_data, dict):\n            with open(svd_data, 'rb') as fd:\n                svd_data = pickle.load(fd)\n        vtr = svd_data['vtr']       # (r x M)\n        A = svd_data['A']\n        A_mu = np.mean(A, axis=0)\n        A_std = np.std(A, axis=0)\n        r, M = vtr.shape\n        ydim = r + 1\n    else:\n        M = 100\n        ydim = M + 1\n\n    # Compute model prediction\n    alpha_rad = np.reshape(np.linspace(0, np.pi/2, M), (1,)*len(x.shape[:-1]) + (M,))\n    y = np.zeros(x.shape[:-1] + (ydim,), dtype=x.dtype)\n    try:\n        # Neutral density\n        n = c4 * P_B + c5  # m^-3\n\n        # Divergence angles\n        alpha1 = c2 * P_B + c3  # Main beam divergence (rad)\n        alpha1[alpha1 &gt; np.pi/2] = np.pi/2\n        alpha2 = alpha1 / c1    # Scattered beam divergence (rad)\n\n        with np.errstate(invalid='ignore', divide='ignore'):\n            A1 = (1 - c0) / ((np.pi ** (3 / 2)) / 2 * alpha1 * np.exp(-(alpha1 / 2)**2) *\n                             (2 * erfi(alpha1 / 2) + erfi((np.pi * 1j - (alpha1 ** 2)) / (2 * alpha1)) -\n                              erfi((np.pi * 1j + (alpha1 ** 2)) / (2 * alpha1))))\n            A2 = c0 / ((np.pi ** (3 / 2)) / 2 * alpha2 * np.exp(-(alpha2 / 2)**2) *\n                       (2 * erfi(alpha2 / 2) + erfi((np.pi * 1j - (alpha2 ** 2)) / (2 * alpha2)) -\n                        erfi((np.pi * 1j + (alpha2 ** 2)) / (2 * alpha2))))\n            I_B = I_B0 * np.exp(-r_m*n*sigma_cex)\n            j_beam = (I_B / r_m ** 2) * A1 * np.exp(-(alpha_rad / alpha1) ** 2)\n            j_scat = (I_B / r_m ** 2) * A2 * np.exp(-(alpha_rad / alpha2) ** 2)\n            j_cex = I_B0 * (1 - np.exp(-r_m*n*sigma_cex)) / (2 * np.pi * r_m ** 2)\n            j = j_beam + j_scat + j_cex\n\n        # Set j~0 where alpha1 &lt; 0 (invalid cases)\n        j[np.where(alpha1 &lt;= 0)] = 1e-20\n        j[np.where(j &lt;= 0)] = 1e-20\n\n        if np.any(abs(j.imag) &gt; 0):\n            LOGGER.warning('Predicted beam current has imaginary component.')\n\n        # Calculate divergence angle from https://aip.scitation.org/doi/10.1063/5.0066849\n        # Requires alpha = [0, ..., 90] deg\n        num_int = j.real * np.cos(alpha_rad) * np.sin(alpha_rad)\n        den_int = j.real * np.cos(alpha_rad)\n\n        with np.errstate(divide='ignore'):\n            cos_div = simps(num_int, alpha_rad, axis=-1) / simps(den_int, alpha_rad, axis=-1)\n            cos_div[cos_div == np.inf] = np.nan\n\n        y[..., 0] = np.arccos(cos_div)  # Divergence angle (rad)\n\n        # Ion current density (A/m^2), in compressed dimension (r) or default dimension (M)\n        y[..., 1:] = np.squeeze(vtr @ ((j.real - A_mu) / A_std)[..., np.newaxis], axis=-1) if compress else j.real\n        return {'y': y, 'cost': 1}\n\n    except Exception as e:\n        raise ModelRunException(f\"Exception in plume model: {e}\")\n</code></pre>"},{"location":"reference/spt100/","title":"SPT-100","text":"<p>Currently, the SPT-100 is the only thruster with data available in <code>hallmd.data</code>. Data for the SPT-100 comes from three sources:</p> <ol> <li>Diamant et al. 2014 - provides thrust, cathode coupling voltage, and ion current density data as a function of chamber background pressure.</li> <li>Macdonald et al. 2019 - provides ion velocity profiles for varying chamber pressures.</li> <li>Sankovic et al. 1993 - provides thrust at varying operating conditions.</li> </ol>"},{"location":"reference/spt100/#citations","title":"Citations","text":"spt100.bib<pre><code>@incollection{diamantEffectBackgroundPressure2014,\n  title = {The {{Effect}} of {{Background Pressure}} on {{SPT-100 Hall Thruster Performance}}},\n  booktitle = {50th {{AIAA}}/{{ASME}}/{{SAE}}/{{ASEE Joint Propulsion Conference}}},\n  author = {Diamant, Kevin D. and Liang, Raymond and Corey, Ron L.},\n  date = {2014-07-25},\n  series = {{{AIAA Propulsion}} and {{Energy Forum}}},\n  publisher = {{American Institute of Aeronautics and Astronautics}},\n  doi = {10.2514/6.2014-3710}\n}\n\n@article{macdonaldBackgroundPressureEffects2019,\n  title = {Background {{Pressure Effects}} on {{Ion Velocity Distributions}} in an {{SPT-100 Hall Thruster}}},\n  author = {Macdonald, Natalia and Pratt, Quinn and Nakles, Michael and Pilgram, Nickolas and Holmes, Michael and Hargus, William},\n  date = {2019-01-11},\n  journaltitle = {Journal of Propulsion and Power},\n  shortjournal = {Journal of Propulsion and Power},\n  volume = {35},\n  pages = {1--10},\n  doi = {10.2514/1.B37133}\n}\n\n@inproceedings{sankovicPerformanceEvaluationRussian1993,\n  title = {Performance Evaluation of the {{Russian SPT-100}} Thruster at {{NASA LeRC}}},\n  author = {Sankovic, J. and Hamley, J. and Haag, T.},\n  date = {1993-09-13/1993-09-16},\n  location = {{Seattle, WA, USA}},\n  url = {https://www.semanticscholar.org/paper/Performance-evaluation-of-the-Russian-SPT-100-at-Sankovic-Hamley/81b7d985669b21aa1a8419277c52e7a879bf3b46},\n  urldate = {2023-01-06},\n  eventtitle = {23rd {{International Electric Propulsion Conference}}}\n}\n</code></pre>"},{"location":"reference/thruster/","title":"Thruster","text":"<p><code>thruster.py</code></p> <p>Module for Hall thruster models.</p> <p>Note</p> <p>Only current implementation is for the 1d fluid Hallthruster.jl code. Other thruster codes can be implemented similarly here. Place extra resources needed by the model in the <code>config</code> directory.</p>"},{"location":"reference/thruster/#hallmd.models.thruster--includes","title":"Includes","text":"<ul> <li><code>hallthruster_jl_input()</code> - Used to format inputs for Hallthruster.jl</li> <li><code>hallthruster_jl_model()</code> - Used to run Hallthruster.jl for a single set of inputs</li> <li><code>hallthruster_jl_wrapper()</code> - The main wrapper function that is compatible with <code>SystemSurrogate</code></li> <li><code>uion_reconstruct()</code> - Convenience function for reconstructing ion velocity profiles from compressed data</li> </ul>"},{"location":"reference/thruster/#hallmd.models.thruster.hallthruster_jl_input","title":"<code>hallthruster_jl_input(thruster_input)</code>","text":"<p>Format inputs for Hallthruster.jl.</p> PARAMETER  DESCRIPTION <code>thruster_input</code> <p>dictionary with all named thruster inputs and values</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>a nested <code>dict</code> in the format that Hallthruster.jl expects to be called</p> Source code in <code>src/hallmd/models/thruster.py</code> <pre><code>def hallthruster_jl_input(thruster_input: dict) -&gt; dict:\n    \"\"\"Format inputs for Hallthruster.jl.\n\n    :param thruster_input: dictionary with all named thruster inputs and values\n    :returns: a nested `dict` in the format that Hallthruster.jl expects to be called\n    \"\"\"\n    anom_model = thruster_input['anom_model']\n    anom_model_coeffs = []\n    if anom_model == \"ShiftedTwoZoneBohm\" or anom_model == \"TwoZoneBohm\":\n        vAN1 = 10 ** thruster_input['vAN1']\n        vAN2 = vAN1 * thruster_input['vAN2']\n        anom_model_coeffs = [vAN1, vAN2]\n    elif anom_model == \"ShiftedGaussianBohm\":\n        vAN1 = 10 ** thruster_input['vAN1']\n        vAN2 = vAN1 * thruster_input['vAN2']\n        vAN3 = thruster_input['vAN3']\n        vAN4 = thruster_input['vAN4']\n        anom_model_coeffs = [vAN1, vAN2, vAN3, vAN4]\n\n    json_data = {\n        # parameters\n        'neutral_temp_K': thruster_input['neutral_temp_K'],\n        'neutral_velocity_m_s': thruster_input['u_n'],\n        'ion_temp_K': thruster_input['ion_temp_K'],\n        'cathode_electron_temp_eV': thruster_input['T_ec'],\n        'sheath_loss_coefficient': thruster_input['c_w'],\n        'inner_outer_transition_length_m': thruster_input['l_t'] * 1e-3,\n        'anom_model_coeffs': anom_model_coeffs,\n        'background_pressure_Torr': 10 ** thruster_input['PB'],\n        'background_temperature_K': thruster_input['background_temperature_K'],\n        'neutral_ingestion_multiplier': thruster_input['f_n'],\n        'apply_thrust_divergence_correction': thruster_input['apply_thrust_divergence_correction'],\n        # design\n        'thruster_name': thruster_input['thruster_name'],\n        'inner_radius': thruster_input['inner_radius'],\n        'outer_radius': thruster_input['outer_radius'],\n        'channel_length': thruster_input['channel_length'],\n        'magnetic_field_file': str(CONFIG_DIR / thruster_input['magnetic_field_file']),\n        'wall_material': thruster_input['wall_material'],\n        'magnetically_shielded': thruster_input['magnetically_shielded'],\n        'anode_potential': thruster_input['Va'],\n        'cathode_potential': thruster_input['V_cc'],\n        'anode_mass_flow_rate': thruster_input['mdot_a'] * 1e-6,\n        'propellant': thruster_input['propellant_material'],\n        # simulation                  \n        'num_cells': thruster_input['num_cells'],\n        'dt_s': thruster_input['dt_s'],\n        'duration_s': thruster_input['duration_s'],\n        'num_save': thruster_input['num_save'],\n        'cathode_location_m': thruster_input['l_c'],\n        'max_charge': thruster_input['max_charge'],\n        'flux_function': thruster_input['flux_function'],\n        'limiter': thruster_input['limiter'],\n        'reconstruct': thruster_input['reconstruct'],\n        'ion_wall_losses': thruster_input['ion_wall_losses'],\n        'electron_ion_collisions': thruster_input['electron_ion_collisions'],\n        'anom_model': thruster_input['anom_model'],\n    }\n\n    if anom_model == 'ShiftedTwoZone' or anom_model == 'ShiftedGaussianBohm':\n        # Add extra parameters for anomalous transport models that depend on pressure\n        json_data.update({'pressure_dz': thruster_input['delta_z'] * thruster_input['channel_length'],\n                          'pressure_z0': thruster_input['z0'] * thruster_input['channel_length'],\n                          'pressure_pstar': thruster_input['p0'] * 1e-6,\n                          'pressure_alpha': thruster_input['alpha']})\n    return json_data\n</code></pre>"},{"location":"reference/thruster/#hallmd.models.thruster.hallthruster_jl_model","title":"<code>hallthruster_jl_model(thruster_input, jl=None)</code>","text":"<p>Run a single Hallthruster.jl simulation for a given set of inputs.</p> PARAMETER  DESCRIPTION <code>thruster_input</code> <p>named key-value pairs of thruster inputs</p> <p> TYPE: <code>dict</code> </p> <code>jl</code> <p>an instance of <code>julicall.Main</code> for running Julia code from within Python</p> <p> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>dict</code> <p><code>dict</code> of Hallthruster.jl outputs for this input</p> RAISES DESCRIPTION <code>ModelRunException</code> <p>if anything fails in <code>juliacall</code></p> Source code in <code>src/hallmd/models/thruster.py</code> <pre><code>def hallthruster_jl_model(thruster_input: dict, jl=None) -&gt; dict:\n    \"\"\"Run a single Hallthruster.jl simulation for a given set of inputs.\n\n    :param thruster_input: named key-value pairs of thruster inputs\n    :param jl: an instance of `julicall.Main` for running Julia code from within Python\n    :raises ModelRunException: if anything fails in `juliacall`\n    :returns: `dict` of Hallthruster.jl outputs for this input\n    \"\"\"\n    # Import Julia\n    if jl is None:\n        from juliacall import Main as jl\n        jl.seval(\"using HallThruster\")\n\n    # Format inputs for Hallthruster.jl\n    json_data = hallthruster_jl_input(thruster_input)\n\n    # Run simulation\n    try:\n        fd = tempfile.NamedTemporaryFile(suffix='.json', encoding='utf-8', mode='w', delete=False)\n        json.dump(json_data, fd, ensure_ascii=False, indent=4)\n        fd.close()\n        t1 = time.time()\n        sol = jl.seval(f'sol = HallThruster.run_simulation(\"{repr(fd.name)[1:-1]}\", verbose=false)')\n        os.unlink(fd.name)   # delete the tempfile\n    except juliacall.JuliaError as e:\n        raise ModelRunException(f\"Julicall error in Hallthruster.jl: {e}\")\n\n    if str(sol.retcode).lower() != \"success\":\n        raise ModelRunException(f\"Exception in Hallthruster.jl: Retcode = {sol.retcode}\")\n\n    # Average simulation results\n    avg = jl.seval(f\"avg = HallThruster.time_average(sol, {thruster_input['time_avg_frame_start']})\")\n\n    # Extract needed data\n    I_B0 = jl.HallThruster.ion_current(avg)[0]\n    niui_exit = 0.0\n    ni_exit = 0.0\n    for Z in range(avg.params.ncharge):\n        ni_exit += jl.seval(f\"avg[:ni, {Z+1}][][end]\")\n        niui_exit += jl.seval(f\"avg[:niui, {Z+1}][][end]\")\n    ui_avg = niui_exit / ni_exit\n\n    # Load simulation results\n    fd = tempfile.NamedTemporaryFile(suffix='.json', encoding='utf-8', mode='w', delete=False)\n    fd.close()\n\n    jl.HallThruster.write_to_json(fd.name, avg)\n    with open(fd.name, 'r') as f:\n        thruster_output = json.load(f)\n    os.unlink(fd.name)  # delete the tempfile\n\n    thrust = thruster_output[0]['thrust']\n    discharge_current = thruster_output[0]['discharge_current']\n\n    thruster_output[0].update({'ui_avg': ui_avg / 1000.0, 'I_B0': I_B0, 'T': thrust, 'I_D': discharge_current,\n                               'eta_c': thruster_output[0]['current_eff'], 'eta_m': thruster_output[0]['mass_eff'],\n                               'eta_v': thruster_output[0]['voltage_eff']})\n\n    # Raise an exception if thrust or beam current are negative (non-physical cases)\n    if thrust &lt; 0 or I_B0 &lt; 0:\n        raise ModelRunException(f'Exception due to non-physical case: thrust={thrust} N, beam current={I_B0} A')\n\n    return thruster_output[0]\n</code></pre>"},{"location":"reference/thruster/#hallmd.models.thruster.hallthruster_jl_wrapper","title":"<code>hallthruster_jl_wrapper(x, alpha=(2, 2), *, compress=False, output_dir=None, n_jobs=-1, config=CONFIG_DIR / 'hallthruster_jl.json', variables=CONFIG_DIR / 'variables_v0.json', svd_data=CONFIG_DIR / 'thruster_svd.pkl', hf_override=None, thruster='SPT-100')</code>","text":"<p>Wrapper function for Hallthruster.jl.</p> <p>Defining input variables</p> <p>This function loads variable definitions from the path specified in <code>variables</code>. The variables are loaded in the form of <code>BaseRV</code> objects from the <code>amisc</code> package. You can directly edit this config file to change the definitions of the variables or add new variables, or you can specify a different file.</p> <p>Dimension reduction</p> <p>If you specify <code>compress=True</code>, then the <code>svd_data</code> will be used to compress the ion velocity profile. The default is a file named <code>thruster_svd.pkl</code> in the <code>config</code> directory. The format of the <code>svd_file</code> is a Python <code>.pkl</code> save file with the fields <code>A</code> \u2192 \\(N\\times M\\) SVD data matrix and <code>vtr</code> \u2192 \\(r\\times M\\) the linear projection matrix from high dimension \\(M\\) to low dimension \\(r\\). See the theory page for more details.</p> PARAMETER  DESCRIPTION <code>x</code> <p><code>(..., xdim)</code> the model inputs, ordering is specified as \"inputs\" in the <code>config</code> file</p> <p> TYPE: <code>ndarray</code> </p> <code>alpha</code> <p>`(\\(\\alpha_1\\), \\(\\alpha_2\\)) model fidelity indices = (\\(N_{cells}\\), \\(N_{charge}\\))</p> <p> TYPE: <code>tuple</code> DEFAULT: <code>(2, 2)</code> </p> <code>compress</code> <p>Whether to compress the ion velocity profile with SVD dimension reduction</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>output_dir</code> <p>path where to save Hallthruster.jl result .json files, none saved if not specified</p> <p> TYPE: <code>str | Path</code> DEFAULT: <code>None</code> </p> <code>n_jobs</code> <p>number of jobs to run in parallel, use all available cpus if -1</p> <p> TYPE: <code>int</code> DEFAULT: <code>-1</code> </p> <code>config</code> <p>path to .json config file to load static thruster simulation configs (.json)</p> <p> TYPE: <code>str | Path</code> DEFAULT: <code>CONFIG_DIR / 'hallthruster_jl.json'</code> </p> <code>variables</code> <p>path to .json file that specifies all input variables</p> <p> TYPE: <code>str | Path</code> DEFAULT: <code>CONFIG_DIR / 'variables_v0.json'</code> </p> <code>svd_data</code> <p>path to a .pkl file that is used to compress the ion velocity profile, can also directly pass in the <code>dict</code> data from the .pkl file</p> <p> TYPE: <code>dict | str | Path</code> DEFAULT: <code>CONFIG_DIR / 'thruster_svd.pkl'</code> </p> <code>hf_override</code> <p>the fidelity indices to override <code>alpha</code></p> <p> TYPE: <code>tuple | bool</code> DEFAULT: <code>None</code> </p> <code>thruster</code> <p>the name of the thruster to simulate (must be defined in <code>config</code>)</p> <p> TYPE: <code>str</code> DEFAULT: <code>'SPT-100'</code> </p> RETURNS DESCRIPTION <p><code>dict(y, files, cost)</code>, the model outputs <code>y=(..., ydim)</code>, list of output files, and avg model cpu time; order of outputs in <code>ydim</code> is specified as \"outputs\" in the <code>config</code> file</p> Source code in <code>src/hallmd/models/thruster.py</code> <pre><code>def hallthruster_jl_wrapper(x: np.ndarray, alpha: tuple = (2, 2), *, compress: bool = False,\n                            output_dir: str | Path = None, n_jobs: int = -1,\n                            config: str | Path = CONFIG_DIR / 'hallthruster_jl.json',\n                            variables: str | Path = CONFIG_DIR / 'variables_v0.json',\n                            svd_data: dict | str | Path = CONFIG_DIR / 'thruster_svd.pkl',\n                            hf_override: tuple | bool = None, thruster: str = 'SPT-100'):\n    \"\"\"Wrapper function for Hallthruster.jl.\n\n    !!! Note \"Defining input variables\"\n        This function loads variable definitions from the path specified in `variables`. The variables are loaded in\n        the form of `BaseRV` objects from the `amisc` package. You can directly edit this config file to change the\n        definitions of the variables or add new variables, or you can specify a different file.\n\n    !!! Info \"Dimension reduction\"\n        If you specify `compress=True`, then the `svd_data` will be used to compress the ion velocity profile. The\n        default is a file named `thruster_svd.pkl` in the `config` directory. The format of the `svd_file` is a Python\n        `.pkl` save file with the fields `A` &amp;rarr; $N\\\\times M$ SVD data matrix and `vtr` &amp;rarr; $r\\\\times M$ the\n        linear projection matrix from high dimension $M$ to low dimension $r$. See the theory page for more details.\n\n    :param x: `(..., xdim)` the model inputs, ordering is specified as \"inputs\" in the `config` file\n    :param alpha: `($\\\\alpha_1$, $\\\\alpha_2$) model fidelity indices = ($N_{cells}$, $N_{charge}$)\n    :param compress: Whether to compress the ion velocity profile with SVD dimension reduction\n    :param output_dir: path where to save Hallthruster.jl result .json files, none saved if not specified\n    :param n_jobs: number of jobs to run in parallel, use all available cpus if -1\n    :param config: path to .json config file to load static thruster simulation configs (.json)\n    :param variables: path to .json file that specifies all input variables\n    :param svd_data: path to a .pkl file that is used to compress the ion velocity profile, can also directly pass in\n                     the `dict` data from the .pkl file\n    :param hf_override: the fidelity indices to override `alpha`\n    :param thruster: the name of the thruster to simulate (must be defined in `config`)\n    :returns: `dict(y, files, cost)`, the model outputs `y=(..., ydim)`, list of output files, and avg model cpu time;\n                                      order of outputs in `ydim` is specified as \"outputs\" in the `config` file\n    \"\"\"\n    x = np.atleast_1d(x)\n    # Check for a single-fidelity override of alpha\n    if isinstance(hf_override, tuple) and len(hf_override) == 2:\n        alpha = hf_override\n    elif hf_override:\n        alpha = (2, 2)\n\n    # Set model fidelity quantities from alpha\n    Ncells = 50 * (alpha[0] + 2)\n    Ncharge = alpha[1] + 1\n    # dt_map = [25e-9, 12.5e-9, 8.4e-9, 6.3e-9]\n    dt_map = [12.5e-9, 8.4e-9, 6.3e-9]\n    dt_s = dt_map[alpha[0]] if Ncharge &lt;= 2 else dt_map[alpha[0]] / np.sqrt(3/2)\n\n    # Constant inputs from config file (thruster geometry, propellant, wall material, simulation params, etc.)\n    with open(Path(config), 'r') as fd:\n        config_data = json.load(fd)\n        default_inputs = load_variables(config_data['default_inputs'], Path(variables))\n        base_input = {var.id: var.nominal for var in default_inputs}  # Set default values for variables.json RV inputs\n        base_input.update(config_data[thruster])                      # Set all other simulation configs\n        input_list = config_data['required_inputs']  # Needs to match xdim and correspond with str input ids to hallthruster.jl\n        output_list = config_data['outputs']\n    base_input.update({'num_cells': Ncells, 'dt_s': dt_s, 'max_charge': Ncharge})  # Update model fidelity params\n\n    # Load svd params for dimension reduction of ion velocity profile\n    if compress:\n        if not isinstance(svd_data, dict):\n            with open(svd_data, 'rb') as fd:\n                svd_data = pickle.load(fd)\n        vtr = svd_data['vtr']  # (r x M)\n        A = svd_data['A']\n        A_mu = np.mean(A, axis=0)\n        A_std = np.std(A, axis=0)\n        r, M = vtr.shape\n        ydim = r + len(output_list) - 1\n    else:\n        M = Ncells + 2\n        ydim = M + len(output_list) - 1\n\n    # Save the inputs to file\n    eval_id = ''.join(random.choices(string.ascii_uppercase + string.digits, k=6))\n    if output_dir is not None:\n        save_dict = {'alpha': alpha, 'x': x}\n        with open(Path(output_dir) / f'{eval_id}_eval.pkl', 'wb') as fd:\n            pickle.dump(save_dict, fd)\n\n    def run_batch(job_num, index_batches, y):\n        \"\"\"Run a batch of indices into the input matrix `x`.\"\"\"\n        from juliacall import Main as jl\n        jl.seval('using HallThruster')\n        thruster_input = copy.deepcopy(base_input)\n        curr_batch = index_batches[job_num]\n        files = []  # Return an ordered list of output filenames corresponding to input indices\n        costs = []  # Time to evaluate hallthruster.jl for a single input\n\n        for i, index in enumerate(curr_batch):\n            x_curr = [float(x[index + (i,)]) for i in range(x.shape[-1])]   # (xdim,)\n            thruster_input.update({input_list[i]: x_curr[i] for i in range(x.shape[-1])})\n\n            # Run hallthruster.jl\n            t1 = time.time()\n            try:\n                res = hallthruster_jl_model(thruster_input, jl=jl)\n            except ModelRunException as e:\n                logger = get_logger(__name__)\n                logger.warning(f'Skipping index {index} due to caught exception: {e}')\n                y[index + (slice(None),)] = np.nan\n                if output_dir is not None:\n                    save_dict = {'input': thruster_input, 'Exception': str(e), 'index': index}\n                    fname = f'{eval_id}_{index}_exc.json'\n                    files.append(fname)\n                    costs.append(0)\n                    data_write(save_dict, fname, output_dir)\n                continue\n\n            # Save QoIs\n            curr_idx = 0\n            for i, qoi_str in enumerate(output_list):\n                if qoi_str == 'uion':\n                    if compress:\n                        # Interpolate ion velocity to the full reconstruction grid (of dim M)\n                        n_cells = M - 2  # M = num of grid pts = Ncells + 2 (half-grid cells at ends of FE domain)\n                        L = thruster_input['l_c']  # Cathode location is the end of axial z domain\n                        dz = L / n_cells\n                        zg = np.zeros(M)  # zg is the axial z grid points for the reconstructed field (of size M)\n                        zg[0] = 0\n                        zg[1] = dz / 2\n                        zg[2:-1] = zg[1] + np.arange(1, n_cells) * dz\n                        zg[-1] = L\n                        z1 = np.atleast_1d(res['z'])\n                        ui1 = np.atleast_1d(res['ui_1'])\n                        uig = np.interp(zg, z1, ui1)  # Interpolated ui on reconstruction grid (M,)\n                        uig_r = np.squeeze(vtr @ ((uig - A_mu) / A_std)[..., np.newaxis], axis=-1)\n                        y[index + (slice(curr_idx, curr_idx + r),)] = uig_r  # Compress to dim (r,)\n                        curr_idx += r\n                    else:\n                        # Otherwise, save entire ion velocity grid\n                        y[index + (slice(curr_idx, curr_idx + M),)] = res['ui_1']\n                        curr_idx += M\n                else:\n                    # Append scalar qois\n                    y[index + (curr_idx,)] = res[qoi_str]\n                    curr_idx += 1\n            costs.append(time.time() - t1)  # Save single model wall clock runtime in seconds (on one cpu)\n\n            # Save to output file (delete redundant results to save space)\n            if output_dir is not None:\n                del res['ni_1']\n                del res['ni_2']\n                del res['ni_3']\n                del res['grad_pe']\n                del res['E']\n                del res['mobility']\n                if Ncharge &lt; 3:\n                    del res['ui_3']\n                    del res['niui_3']\n                if Ncharge &lt; 2:\n                    del res['ui_2']\n                    del res['niui_2']\n                save_dict = {'input': thruster_input, 'output': res}\n                fname = f'{eval_id}_{index}.json'\n                files.append(fname)\n                data_write(save_dict, fname, output_dir)\n\n        return files, costs\n\n    # Evenly distribute input indices across batches\n    num_batches = cpu_count() if n_jobs &lt; 0 else min(n_jobs, cpu_count())\n    index_batches = [list() for i in range(num_batches)]\n    flat_idx = 0\n    for input_index in np.ndindex(*x.shape[:-1]):\n        # Cartesian product iteration over x.shape indices\n        index_batches[flat_idx % num_batches].append(input_index)\n        flat_idx += 1\n\n    # Allocate space for outputs and compute model (in parallel batches)\n    set_loky_pickler('cloudpickle')     # Dill can't serialize mmap objects, but cloudpickle can\n    with tempfile.NamedTemporaryFile(suffix='.dat', mode='w+b', delete=False) as y_fd:\n        pass\n    y = np.memmap(y_fd.name, dtype='float32', mode='r+', shape=x.shape[:-1] + (ydim,))\n    with Parallel(n_jobs=n_jobs, verbose=0) as ppool:\n        res = ppool(delayed(run_batch)(job_num, index_batches, y) for job_num in range(num_batches))\n    y_ret = np.empty(y.shape)\n    y_ret[:] = y[:]\n    del y\n    os.unlink(y_fd.name)\n\n    # Re-order the resulting list of file names and costs\n    files, costs = [], []\n    flat_idx = 0\n    for input_index in np.ndindex(*x.shape[:-1]):\n        # Iterate in same circular fashion as the inputs were passed to parallel\n        batch_files, batch_costs = res[flat_idx % num_batches]\n        if output_dir is not None:\n            files.append(batch_files.pop(0))\n        costs.append(batch_costs.pop(0))\n        flat_idx += 1\n\n    # Save model eval summary to file\n    if output_dir is not None:\n        save_dict = {'alpha': alpha, 'x': x, 'y': y_ret, 'is_compressed': compress, 'files': files, 'costs': costs}\n        with open(Path(output_dir) / f'{eval_id}_eval.pkl', 'wb') as fd:\n            pickle.dump(save_dict, fd)\n    costs = np.atleast_1d(costs).astype(np.float64)\n    costs[costs == 0] = np.nan\n    avg_model_cpu_time = np.nanmean(costs)\n\n    return {'y': y_ret, 'files': files, 'cost': avg_model_cpu_time}\n</code></pre>"},{"location":"reference/thruster/#hallmd.models.thruster.uion_reconstruct","title":"<code>uion_reconstruct(xr, z=None, L=0.08, svd_data=CONFIG_DIR / 'thruster_svd.pkl')</code>","text":"<p>Reconstruct an ion velocity profile, interpolate to <code>z</code> if provided.</p> <p>Warning</p> <p>The <code>svd_data</code> must be the same as was used with <code>hallthruster_jl_wrapper</code> when compressing the data, i.e. the same SVD data must be used to reconstruct here.</p> PARAMETER  DESCRIPTION <code>xr</code> <p><code>(... r)</code> The reduced dimension output of <code>hallthruster_jl_wrapper</code> (just the ion velocity profile)</p> <p> TYPE: <code>ndarray</code> </p> <code>z</code> <p><code>(Nz,)</code> The axial <code>z</code> grid points to interpolate to (in meters, between 0 and <code>L</code>)</p> <p> TYPE: <code>ndarray</code> DEFAULT: <code>None</code> </p> <code>L</code> <p><code>(...,)</code> The full domain length of the reconstructed grid(s)</p> <p> TYPE: <code>float | ndarray</code> DEFAULT: <code>0.08</code> </p> <code>svd_data</code> <p>path to a <code>.pkl</code> file that is used to compress/reconstruct the ion velocity profile, can also pass the <code>dict</code> of svd data directly in</p> <p> TYPE: <code>dict | str | Path</code> DEFAULT: <code>CONFIG_DIR / 'thruster_svd.pkl'</code> </p> RETURNS DESCRIPTION <code>tuple[ndarray, ndarray]</code> <p><code>z, uion_interp</code> - <code>(..., Nz or M)</code> The reconstructed (and potentially interpolated) ion velocity profile(s), corresponds to <code>z=(0, 0.08)</code> m with <code>M=202</code> points by default</p> Source code in <code>src/hallmd/models/thruster.py</code> <pre><code>def uion_reconstruct(xr: np.ndarray, z: np.ndarray = None, L: float | np.ndarray = 0.08,\n                     svd_data: dict | str | Path = CONFIG_DIR / 'thruster_svd.pkl') -&gt; tuple[np.ndarray, np.ndarray]:\n    \"\"\"Reconstruct an ion velocity profile, interpolate to `z` if provided.\n\n    !!! Warning\n        The `svd_data` must be the **same** as was used with `hallthruster_jl_wrapper` when compressing the data, i.e.\n        the same SVD data must be used to reconstruct here.\n\n    :param xr: `(... r)` The reduced dimension output of `hallthruster_jl_wrapper` (just the ion velocity profile)\n    :param z: `(Nz,)` The axial `z` grid points to interpolate to (in meters, between 0 and `L`)\n    :param L: `(...,)` The full domain length of the reconstructed grid(s)\n    :param svd_data: path to a `.pkl` file that is used to compress/reconstruct the ion velocity profile, can also pass\n                     the `dict` of svd data directly in\n    :returns: `z, uion_interp` - `(..., Nz or M)` The reconstructed (and potentially interpolated) ion velocity\n              profile(s), corresponds to `z=(0, 0.08)` m with `M=202` points by default\n    \"\"\"\n    if z is not None:\n        z = z.astype(xr.dtype)\n    L = np.atleast_1d(L)\n    interp_normal = len(L.shape) == 1 and L.shape[0] == 1\n\n    # Load SVD data from file\n    if not isinstance(svd_data, dict):\n        with open(svd_data, 'rb') as fd:\n            svd_data = pickle.load(fd)\n    vtr = svd_data['vtr']       # (r x M)\n    A = svd_data['A']\n    A_mu = np.mean(A, axis=0)\n    A_std = np.std(A, axis=0)\n    r, M = vtr.shape\n\n    n_cells = M - 2\n    dz = L / n_cells\n    zg = np.zeros(L.shape + (M,))  # zg is the axial z grid points for the reconstructed field (of size M)\n    zg[..., 1] = dz / 2\n    zg[..., 2:-1] = zg[..., 1, np.newaxis] + np.arange(1, n_cells) * dz[..., np.newaxis]\n    zg[..., -1] = L\n    uion_g = (np.squeeze(vtr.T @ xr[..., np.newaxis], axis=-1) * A_std + A_mu).astype(xr.dtype)      # (..., M)\n    zg = (np.squeeze(zg, axis=0) if interp_normal else zg).astype(xr.dtype)    # (..., M)\n\n    # Do vectorized 1d linear interpolation\n    if z is not None:\n        diff = zg[..., np.newaxis] - z                          # (..., M, Nz)\n        lower_idx = np.argmin(np.abs(diff), axis=-2)            # (..., Nz)\n        diff = np.take_along_axis(zg, lower_idx, axis=-1) - z\n        lower_idx[diff &gt; 0] -= 1\n        upper_idx = lower_idx + 1\n        lower_idx[lower_idx &lt; 0] = 0\n        upper_idx[upper_idx &gt;= zg.shape[-1]] = zg.shape[-1] - 1\n        x_lower = np.take_along_axis(zg, lower_idx, axis=-1)\n        x_upper = np.take_along_axis(zg, upper_idx, axis=-1)\n        if interp_normal:\n            y_lower = uion_g[..., lower_idx]\n            y_upper = uion_g[..., upper_idx]\n        else:\n            # Vectorized 1d interpolation\n            y_lower = np.take_along_axis(uion_g, lower_idx, axis=-1)\n            y_upper = np.take_along_axis(uion_g, upper_idx, axis=-1)\n\n        with np.errstate(divide='ignore', invalid='ignore'):\n            uion_interp = y_lower + (z - x_lower) * (y_upper-y_lower) / (x_upper-x_lower)       # (..., Nz)\n\n        # Set points outside grid equal to outer values\n        lower_idx = z &lt; zg[..., 0, np.newaxis]      # (..., Nz)\n        upper_idx = z &gt; zg[..., -1, np.newaxis]     # (..., Nz)\n        if interp_normal:\n            if np.any(lower_idx):\n                uion_interp[..., lower_idx] = uion_g[..., 0, np.newaxis]\n            if np.any(upper_idx):\n                uion_interp[..., upper_idx] = uion_g[..., -1, np.newaxis]\n        else:\n            uion_interp[lower_idx] = uion_g[np.any(lower_idx, axis=-1), 0]\n            uion_interp[upper_idx] = uion_g[np.any(upper_idx, axis=-1), -1]\n\n        return z, uion_interp\n    else:\n        return zg, uion_g\n</code></pre>"},{"location":"reference/utils/","title":"Utilities","text":"<p><code>utils.py</code></p> <p>Module to provide utilities for the <code>hallmd</code> package.</p>"},{"location":"reference/utils/#hallmd.utils--includes","title":"Includes","text":"<ul> <li><code>ModelRunException</code> - Used to note when a model has encountered an unknown error.</li> <li><code>data_write()</code> - Convenience function for writing .json data to file.</li> <li><code>plot_qoi()</code> - Convenience plotting tool for showing QoI with UQ bounds</li> </ul>"},{"location":"reference/utils/#hallmd.utils.ModelRunException","title":"<code>ModelRunException</code>","text":"<p>             Bases: <code>Exception</code></p> <p>Custom exception to note when a model has encountered an unknown error while executing.</p>"},{"location":"reference/utils/#hallmd.utils.data_write","title":"<code>data_write(data, filename, write_dir='.')</code>","text":"<p>Convenience function to write .json data files.</p> Source code in <code>src/hallmd/utils.py</code> <pre><code>def data_write(data, filename, write_dir='.'):\n    \"\"\"Convenience function to write .json data files.\"\"\"\n    with open(Path(write_dir) / filename, 'w', encoding='utf-8') as fd:\n        json.dump(data, fd, ensure_ascii=False, indent=4)\n</code></pre>"},{"location":"reference/utils/#hallmd.utils.model_config_dir","title":"<code>model_config_dir()</code>","text":"<p>Return a path to the model configuration directory</p> Source code in <code>src/hallmd/utils.py</code> <pre><code>def model_config_dir():\n    \"\"\"Return a path to the model configuration directory\"\"\"\n    return resources.files('hallmd.models.config')\n</code></pre>"},{"location":"reference/utils/#hallmd.utils.plot_qoi","title":"<code>plot_qoi(ax, x, qoi, xlabel, ylabel, legend=False)</code>","text":"<p>Plot a quantity of interest with 5%, 50%, 95% percentiles against <code>x</code>.</p> PARAMETER  DESCRIPTION <code>ax</code> <p>matplotlib Axes object to plot on</p> <p> </p> <code>x</code> <p><code>(Nx,)</code> array to plot on <code>x</code> axis</p> <p> </p> <code>qoi</code> <p><code>(Nx, Ns,)</code> samples of the QOI at each <code>x</code> location</p> <p> </p> <code>xlabel</code> <p>label for the x-axis</p> <p> </p> <code>ylabel</code> <p>label for the y-axis</p> <p> </p> <code>legend</code> <p>whether to plot a legend</p> <p> DEFAULT: <code>False</code> </p> Source code in <code>src/hallmd/utils.py</code> <pre><code>def plot_qoi(ax, x, qoi, xlabel, ylabel, legend=False):\n    \"\"\" Plot a quantity of interest with 5%, 50%, 95% percentiles against `x`.\n\n    :param ax: matplotlib Axes object to plot on\n    :param x: `(Nx,)` array to plot on `x` axis\n    :param qoi: `(Nx, Ns,)` samples of the QOI at each `x` location\n    :param xlabel: label for the x-axis\n    :param ylabel: label for the y-axis\n    :param legend: whether to plot a legend\n    \"\"\"\n    p5 = np.percentile(qoi, 5, axis=1)\n    med = np.percentile(qoi, 50, axis=1)\n    p95 = np.percentile(qoi, 95, axis=1)\n    ax.plot(x, med, '-k', label='Model')\n    ax.fill_between(x, p5, p95, alpha=0.4, edgecolor=(0.4, 0.4, 0.4), facecolor=(0.8, 0.8, 0.8))\n    ax_default(ax, xlabel, ylabel, legend=legend)\n</code></pre>"}]}